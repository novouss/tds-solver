{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠️ WARNING\n",
    "\n",
    "This notebook isn't directly used for the API and is only intended for the development process of the project. \n",
    "\n",
    "Please remove the following to ensure a clean production build\n",
    "\n",
    "```bash\n",
    "uv remove ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Assistance\n",
    "\n",
    "This section is specialized in utilizing local llms such as Ollama's `llama3.2` model to create documentations. This works in tandem to [data_preparations.ipynb](data_preparations.ipynb) for text embedding the docstrings of a function inside the `./submission` module.\n",
    "\n",
    "The purpose of creating this localized assistance is to generate texts without dealing with internet or server issues from other GPT models and capping out token usages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing ollama\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing a model\n",
    "\n",
    "```bash\n",
    "ollama run llama3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama Python Library\n",
    "\n",
    "```bash\n",
    "uv add ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You create docstrings for functions provided by the user. These are the rules for your output\n",
    "    - Keep the docstrings short but very specific and clear as to what the function does. \n",
    "    - Ensure that this content is in Google Python Style.\n",
    "    - Ensure that it us a valid docstring for the ast Python library.\n",
    "    - You only have to provide the docstring, there's no need to write the code only the docstring, use this format below as a guide for your answer.\n",
    "    - Do a double check on your output before providing an answer.\n",
    "\n",
    "    \\\"\"\"\n",
    "    docstring\n",
    "    \n",
    "    Args:\n",
    "        param1 (str): A description of param1\n",
    "        param2 (str): A description of param2\n",
    "    \n",
    "    Returns:\n",
    "        int: A description of the output\n",
    "    \n",
    "    Raises:\n",
    "        Type of error: A description of the error\n",
    "    \n",
    "    Example:\n",
    "        >>> example(\"hello\", \"world\")\n",
    "        hello world\n",
    "    \\\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def ask_something(prompt: str):\n",
    "    response = ollama.chat(\n",
    "        model = \"llama3.2\",\n",
    "        messages=[\n",
    "            { \"role\": \"user\", \"content\": prompt }\n",
    "        ]\n",
    "    )\n",
    "    return str(response[\"message\"][\"content\"])\n",
    "\n",
    "def create_docstring(prompt: str):\n",
    "    response = ollama.chat(\n",
    "       model = \"llama3.2\",\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"content\": system_prompt },\n",
    "            { \"role\": \"user\", \"content\": prompt }\n",
    "        ]\n",
    "    )\n",
    "    return str(response[\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docstring exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_docstring(\"\"\"\n",
    "def yt_transcribe(url: str) -> str:\n",
    "    def clean_transcripts(df_export: pd.DataFrame) -> list[str]:\n",
    "        export = df_export.to_string(index=False)\n",
    "        export = export.split(\"\\n\")\n",
    "        for idx, text in enumerate(export):\n",
    "            export[idx] = text.strip()\n",
    "        return export\n",
    "    def download_audio(url: str, filename: str) -> None:\n",
    "        ydl_opts = {\n",
    "            \"format\": \"ba[abr<50]/worstaudio\",\n",
    "            \"postprocessors\": [{\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"32\"\n",
    "            }],\n",
    "            \"outtmpl\": f\"./data/{video_code}.%(ext)s\",\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "    video_code = url.split(\"=\")[1]\n",
    "    if not os.path.isfile(f\"./data/{video_code}.mp3\"):\n",
    "        download_audio(url, video_code)\n",
    "    audio = open(f\"./data/{video_code}.mp3\", \"rb\")\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        file=audio,\n",
    "        model=\"whisper-1\",\n",
    "        response_format=\"verbose_json\",\n",
    "        timestamp_granularities=[\"word\"]\n",
    "    )\n",
    "    words = json.loads(transcription.to_json())[\"words\"]\n",
    "    df = pd.DataFrame(words)\n",
    "    clip = df[(df[\"start\"] >= 173.4) & (df[\"end\"] <= 229.7)][\"word\"]\n",
    "    count = []\n",
    "    for i in clean_transcripts(clip):\n",
    "        if ord(i[0]) <= 90 and not (i == \"Miranda\" or i == \"Edmund\"):\n",
    "            count.append(\".\")\n",
    "        count.append(i)\n",
    "    return str(len(count))\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_something(\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# Function to increment each digit in a given string\n",
    "increment_digits() {\n",
    "\techo \"$1\" | tr '0123456789' '1234567890'\n",
    "}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for FILE in *; do\n",
    "\t# Check if the file has numbers\n",
    "\tif [[ $FILE =~ [0-9] ]]; then\n",
    "    \t# Replace numbers with incremented numbers\n",
    "    \tNEW_FILE=$(increment_digits \"$FILE\")\n",
    "   \t \n",
    "    \t# Check if the new filename already exists to avoid overwriting\n",
    "    \tif [[ -e $NEW_FILE ]]; then\n",
    "        \techo \"Cannot rename $FILE to $NEW_FILE because $NEW_FILE already exists.\"\n",
    "    \telse\n",
    "        \tmv \"$FILE\" \"$NEW_FILE\"\n",
    "    \tfi\n",
    "\tfi\n",
    "done\n",
    "\n",
    "give me the python code equivalent to this bash script\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
